# Awesome Papers for this project distinguished by research groups [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
Awesome works and resources relevant to 360 vision.

Suggestions or pull requests are welcome.
Inspired by [awesome-deep-vision](https://github.com/kjw0612/awesome-deep-vision), 
[awesome-adversarial-machine-learning](https://github.com/yenchenlin/awesome-adversarial-machine-learning), 
[awesome-deep-learning-papers](https://github.com/terryum/awesome-deep-learning-papers), 
[awesome-architecture-search](https://github.com/markdtw/awesome-architecture-search/blob/master/README.md),
and [awesomeCVPapers](https://github.com/lucas-althoff/awesomeCVpapers)

## Table of Contents

- [Projects By Research Groups](# By Group)
- [Paper](#paper)
  - [Field of View Piloting, Saliency View Detection](#)
  - [6DOF, 3D, SLAM, Navigation](#)
  - [Stabilization](#)
  - [Natural Language](#)
  - [Spherical DNN](#)
  - [Human Interaction](#)
  - [Multi-camera](#)
- [Dataset](#dataset)
- [Media](#media)
- [Awesome CV papers](#Awesome CV papers)

# By Group

### Min Sun Projects (China + EUA)

Tell Me Where to Look: Investigating Ways for Assisting Focus in 360° Video (Min Sun, 2017) [Video1]() [Video2](https://www.youtube.com/watch?v=lsT0D07zuk0) [Project](http://aliensunmin.github.io/project/360video-study/)
Yen-Chen Lin, Yung-Ju Chang, Hou-Ning Hu, Hsien-Tzu Cheng, Chi-Wen Huang, Min Sun (2017)

Deep 360 Pilot: Learning a Deep Agent for Piloting through 360° Sports Video [Video] [Project]
Hou-Ning Hu*, Yen-Chen Lin*, Ming-Yu Liu, Hsien-Tzu Cheng, Yung-Ju Chang, Min Sun (2017)

Cube Padding for Weakly-Supervised Saliency Prediction in 360° Videos [Video] [Project]
Hsien-Tzu Cheng,  Chun-Hung Chao,  Jin-Dong Dong,  Hao-Kai Wen,  Tyng-Luh Liu,  Min Sun (2018)

### Prof. Sassatelli Projects (France)


### Prof Gutierrez (Spain + EUA)

## Paper
### Field of View Piloting & Saliency View Detection
- A Deep Ranking Model for Spatio-Temporal Highlight Detection from a 360 Video [[PDF]](https://arxiv.org/abs/1801.10312)
    - Youngjae Yu et al., *AAAI*, 2018.
- SaltiNet: Scan-path Prediction on 360 Degree Images using Saliency Volumes [[PDF]](https://arxiv.org/abs/1707.03123) [[Project]](https://imatge.upc.edu/web/publications/saltinet-scan-path-prediction-360-degree-images-using-saliency-volumes)
    - Assens M et al., *ICCVW*, 2017.
- SalNet360: Saliency Maps for omni-directional images with CNN [[PDF]](https://arxiv.org/pdf/1709.06505)
    - Rafael Monroy et al., *arXiv*, 2017.
- Deep 360 Pilot: Learning a Deep Agent for Piloting through 360° Sports Video [[PDF]](https://arxiv.org/abs/1705.01759) [[Project]](https://aliensunmin.github.io/project/360video/)
    - Hou-Ning Hu et al., *CVPR*, 2017.
- Making 360° Video Watchable in 2D: Learning Videography for Click Free Viewing [[PDF]](https://arxiv.org/abs/1703.00495) [[Project]](http://vision.cs.utexas.edu/projects/watchable360/)
    - Yu-Chuan Su et al., *CVPR*, 2017.
- Semantic-driven Generation of Hyperlapse from 360° Video [[PDF]](https://arxiv.org/pdf/1703.10798.pdf) [[Project]](http://vllab.ucmerced.edu/wlai24/360hyperlapse/)
    - Wei-Sheng Lai et al., *TVCG*, 2017.
- Viewport-aware adaptive 360° video streaming using tiles for virtual reality [[PDF]](https://ieeexplore.ieee.org/document/8296667/)
    - Cagri Ozcinar et al., *ICIP*, 2017.  
- Visual Attention in Omnidirectional Video for Virtual Reality Applications [[PDF]](https://github.com/cozcinar/omniAttention/blob/master/OmniAttention2018.pdf) [[Project]](https://github.com/cozcinar/omniAttention/)
    - Cagri Ozcinar and Aljosa Smolic, *QoMEX*, 2018.
- Look around you: Saliency maps for omnidirectional images in VR applications [[PDF]](https://ieeexplore.ieee.org/document/7965634/)
    - Ana De Abreu et al., *QoMEX*, 2017.
- Viewport-adaptive navigable 360-degree video delivery [[PDF]](http://ieeexplore.ieee.org/document/7996611/)
    - Xavier Corbillon et al., *ICC*, 2017.
- Pano2vid: Automatic cinematography for watching 360° videos [[PDF]](http://vision.cs.utexas.edu/projects/Pano2Vid/accv2016-0327su.pdf) [[Project]](http://vision.cs.utexas.edu/projects/Pano2Vid/)
    - Yu-Chuan Su et al., *ACCV*, 2016.

### 6DOF, 3D, SLAM, Navigation
- Omnidirectional CNN for Visual Place Recognition and Navigation [[PDF]](https://arxiv.org/abs/1803.04228)
    - Tsun-Hsuan Wang et al. *arXiv*, 2018.
- Structure-From-Motion in Spherical Video Usingthe von Mises-Fisher Distribution [[PDF]](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7707455)
    - HaoGua et al., *TIP*, 2017.
- 6-DOF VR videos with a single 360-camera [[PDF]](https://pdfs.semanticscholar.org/a88a/986372a551ca2581783c9ac6750513cde7df.pdf)
    - Jingwei Huang et al., *IEEE VR*, 2017.
- Depth augmented stereo panorama for cinematic virtual reality with head-motion parallax [[PDF]](https://web.stanford.edu/~jbboin/doc/2016_ICME.pdf)
    - Jayant Thatte et al., *ICME*, 2016.
- 3D reconstruction of structures using spherical cameras with small motion [[PDF]](http://ieeexplore.ieee.org/document/7832307/)
    - Sarthak Pathak et al., *ICCAS*, 2016.
- Large-scale direct slam for omnidirectional cameras [[PDF]](https://vision.in.tum.de/_media/spezial/bib/caruso2015_omni_lsdslam.pdf)
    - David Caruso et al., *IROS*, 2015.
- Omnidirectional 3D reconstruction in augmented Manhattan worlds [[PDF]](http://www.cvlibs.net/publications/Schoenbein2014IROS.pdf)
    - Miriam Sch ̈onbein et al., *IROS*, 2014.
- Moving object detection, tracking and following using an omnidirectional camera on a mobile robot [[PDF]](http://www.irisa.fr/lagadic/pdf/2014_icra_markovic.pdf)
    - Ivan Markovic et al., *ICRA*, 2014.
- Structure from Motion using full spherical panoramic cameras [[PDF]](http://ieeexplore.ieee.org/document/6130266/)
    - Alain Pagani et al., *ICCVW*, 2011.

### Stabilization
- 360° video stabilization [[PDF]](https://dl.acm.org/citation.cfm?id=2982405)
    - Johannes Kopf et al., *TOG*, 2016

### Natural Language
- Self-view Grounding Given a Narrated 360 Video [[PDF]](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/11/AAAI_CameraReady_finalversion.pdf)
    - Shih-Han Chou et al., *AAAI*, 2017.

### Spherical DNN
- Spherical CNNs [[PDF]](https://arxiv.org/abs/1801.10130) 
    - Taco S. Cohen et al., *ICLR*, 2018.
- Learning Spherical Convolution for Fast Features from 360° Imagery [[PDF]](https://papers.nips.cc/paper/6656-learning-spherical-convolution-for-fast-features-from-360-imagery.pdf)
    - Yu-Chuan Su et al., *NIPS*, 2017.

### Human Interaction
- Tell Me Where to Look: Investigating Ways for Assisting Focus in 360° Video [[PDF]](https://drive.google.com/file/d/0B50cbskLVq-eRmN1U3M4ZHhvM2M/view) [[Project]](https://aliensunmin.github.io/project/360video-study/)
    - Yen-Chen Lin et al., *CHI*, 2017.
- Outside-In: Visualizing Out-of-Sight Regions-of-Interest in a 360 Video Using Spatial Picture-in-Picture Previews [[PDF]](https://dl.acm.org/citation.cfm?id=3126594.3126656)
    - Yung-Ta Lin et al., *UIST*, 2017.

### Multi-camera
- A Multi-View Stereo Benchmark with High-Resolution Images and Multi-Camera Videos in Unstructured Scenes [[PDF]](www.cvlibs.net/publications/Schoeps2017CVPR.pdf)
    - T. Schöps et al., *CVPR*, 2017.
- 3D Visual Perception for Self-Driving Cars using a Multi-Camera System: Calibration, Mapping, Localization, and Obstacle Detection [[PDF]](https://arxiv.org/abs/1708.09839)
    - C. Häne et al., *IMAVIS*, 2017.

## Dataset
- Visual Attention in Omnidirectional Video for Virtual Reality Applications [[Website]](https://github.com/cozcinar/omniAttention/)
- synthia-dataset [[Website]](http://synthia-dataset.net/)
    - 8 RGB cameras forming a binocular 360º camera, 8 depth sensors -> RGB & Depth in 360º
    - 2018
- SALIENT 360! [[Website]](https://www.technicolor.com/dream/research-innovation/salient-dataset)
    - A Dataset of Head and Eye Movements for 360 Degree Images, Rai et al., *MMSys*, 2017.
- 360-Degree Videos Head Movements Dataset [[Website]](http://dash.ipv6.enstb.fr/headMovements/#structure)
    - 360-Degree Video Head Movement Dataset, Corbillon et al., *MMSys*, 2017.
- SUN360 [[Website]](http://people.csail.mit.edu/jxiao/SUN360/)
    - Recognizing Scene Viewpoint using Panoramic Place Representation, Xiao et al., *CVPR*, 2012.

## Media
- facebook 360 [[Website]](https://facebook360.fb.com/editing-360-photos-injecting-metadata/)
- facebook cubemap [[Website]](https://code.facebook.com/posts/1638767863078802/under-the-hood-building-360-video/)
- facebook 360 heatmap [[Website]](https://www.facebook.com/facebookmedia/get-started/discovery-tools-insights)
- youtube 360 heatmap [[Website]](https://youtube-creators.googleblog.com/2017/06/hot-and-cold-heatmaps-in-vr.html)

# Awesome CV papers

### Video Descriptor
![Video Descriptor](https://farm1.staticflickr.com/635/23072596460_fe71dd4235.jpg)

(from Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, Manohar Paluri, `Learning Spatiotemporal Features with 3D Convolutional Networks`, 	ICCV15'. )
 * C3D, Facebook AI Research [[Paper]](http://arxiv.org/pdf/1412.0767v4.pdf) [[Project Page]](http://vlg.cs.dartmouth.edu/c3d/) __Hao__
  * Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, Manohar Paluri, `Learning Spatiotemporal Features with 3D Convolutional Networks`, 	ICCV15'.
 * CNN with VLAD, The University of Queensland [[Paper]](http://arxiv.org/pdf/1411.4006v1.pdf) __Hao__
  * Zhongwen Xu, Yi Yang, Alexander G. Hauptmann, `A Discriminative CNN Video Representation for Event Detection`, 	CVPR15'.

### Video Description Generation
![Video Description](https://farm1.staticflickr.com/704/23192389896_db00b3d27d_n.jpg)

(from Li Yao, Atousa Torabi, Kyunghyun Cho, Nicolas Ballas, Christopher Pal, Hugo Larochelle, Aaron Courville, `Describing Videos by Exploiting Temporal Structure`, 	ICCV15'. )
 * HRNE, Zhejiang University [[Paper]](http://arxiv.org/pdf/1511.03476v1.pdf) __Hao__
  * Pingbo Pan, Zhongwen Xu, Yi Yang, Fei Wu, Yueting Zhuang, `Hierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning`, arXiv:1511.03476. 
 * LSTM with CNN+3DCNN & Attention Mechanism, Universite ́ de Montre ́al [[Paper]](http://arxiv.org/pdf/1502.08029v5.pdf) __Hao__
  * Li Yao, Atousa Torabi, Kyunghyun Cho, Nicolas Ballas, Christopher Pal, Hugo Larochelle, Aaron Courville, `Describing Videos by Exploiting Temporal Structure`, 	ICCV15'. 
 * Video caption via LSTM, UT Austin [[Paper]](http://arxiv.org/pdf/1412.4729v3.pdf) [[Project Page]](https://www.cs.utexas.edu/~vsub/naacl15_project.html) __Hao__
  * Subhashini Venugopalan, Huijuan Xu, Jeff Donahue, Marcus Rohrbach, Raymond Mooney, Kate Saenko, `Translating Videos to Natural Language Using Deep Recurrent Neural Networks`, 	ICCV15'. 
 * LSTM-E, Microsoft Research, Beijing [[Paper]](http://arxiv.org/pdf/1505.01861v3.pdf) __Hao__
  * Yingwei Pan, Tao Mei, Ting Yao, Houqiang Li, Yong Rui, `Jointly Modeling Embedding and Translation to Bridge Video and Language`, 		arXiv:1505.01861. 
 * p-RNN, Purdue University, Baidu Research - Institute of Deep Learning [[Paper]](http://arxiv.org/pdf/1510.07712v1.pdf) __Hao__
  * Haonan Yu, Jiang Wang, Zhiheng Huang, Yi Yang, Wei Xu, `Video Paragraph Captioning using Hierarchical Recurrent Neural Networks`, 			arXiv:1510.07712. 

### Wrist Camera

 * WristCam System, The University of Tokyo [[Paper]](http://arxiv.org/pdf/1511.06783v1.pdf) __JamesChan__
  * Katsunori Ohnishi, Atsushi Kanehira, Asako Kanezaki, Tatsuya Harada, `ecognizing Activities of Daily Living with a Wrist-mounted Camera`, arXiv:1511.06783v1.


### Optical Flow

 * `Farneback's algorithm : Two-Frame Motion Estimation Based on Polynomial Expansion`[[PAPER]](http://home.isr.uc.pt/~henriques/publications/henriques_nips2014.pdf) __jimcheng__
  *Joao F. Henriques Pedro Martins Rui Caseiro Jorge Batista˜,Institute of Systems and Robotics
University of Coimbra


* LEAR PROJECT of deep and epic flow [[PROJECT PAGE]](http://lear.inrialpes.fr/src/deepmatching/) 
*`DeepMatching: Deep Convolutional Matching`. DeepMatching was recently used to improve the estimation of optical flow in several methods like DeepFlow and EpicFlow (joint work with Philippe Weinzaepfel, Zaid Harchaoui, Cordelia Schmid).

* `DeepFlow: Large displacement optical flow with deep matching`[[PAPER]](https://hal.inria.fr/hal-00873592/document) __jimcheng__
  *Philippe Weinzaepfel, J´erˆome Revaud, Zaid Harchaoui, Cordelia Schmid. ICCV, Dec 2013, Sydney, Australia. IEEE, pp.1385-1392, 2013, <10.1109/ICCV.2013.175>. <hal-00873592>
* `EpicFlow: Edge-Preserving Interpolation of Correspondences for Optical Flow`[[PAPER]](https://hal.inria.fr/hal-01142656/document) __jimcheng__
  *Jerome Revaud, Philippe Weinzaepfel, Zaid Harchaoui, Cordelia Schmid. CVPR, Jun 2015, Boston, United States. <hal-01142656>


### Hardware Accelaration

* `Parallel Architecture for Hierarchical Optical Flow Estimation Based on FPGA`[[PAPER]](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5772045&tag=1) __jimcheng__
  *Francisco Barranco, Matteo Tomasi, Javier Diaz, Mauricio Vanegas, and Eduardo Ros, IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS, VOL. 20, NO. 6, pp.1058-1067, JUNE 2012.

* `Efficient Hardware Implementation of the Horn-Schunck Algorithm for High-Resolution Real-Time Dense Optical Flow Sensor`[[PAPER]](http://www.mdpi.com/1424-8220/14/2/2860/pdf) __jimcheng__
  *Mateusz Komorkiewicz *, Tomasz Kryjak and Marek Gorgon, AGH University of Science and Technology, al. Sensors 2014, 14, 2860-2891; doi:10.3390/s140202860.

* `Caffe con Troll: Shallow Ideas to Speed Up Deep Learning`[[PAPER]](http://arxiv.org/abs/1504.04343) __jimcheng__
  *Stefan Hadjis† Firas Abuzaid† Ce Zhang†‡ Christopher Ré, Stanford University, University of Wisconsin-Madison, arXiv:1504.04343v2 [cs.LG] 26 May 2015.
* `cuDNN: Efficient Primitives for Deep Learning`[[PAPER]](http://arxiv.org/abs/1410.0759) __jimcheng__
  *Sharan Chetlur, Cliff Woolley, Philippe Vandermersch, Jonathan Cohen, John Tran, NVIDIA, Santa Clara, CA 95050, arXiv:1410.0759v3 [cs.NE] 18 Dec 2014.
